{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# K-NN",
   "id": "4c7cea4fba525779"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "import pandas as pd",
   "id": "674f42349da7d56"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## I. Chuẩn bị dữ liệu",
   "id": "2b0c30e0117dc868"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df = pd.read_csv('../Dataset/archive/WA_Fn-UseC_-HR-Employee-Attrition.csv')",
   "id": "4db3d65faff84870"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df",
   "id": "918bf1256ef0a722"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X = df.drop(['Attrition', 'EmployeeNumber'], axis=1)\n",
    "y = df['Attrition']"
   ],
   "id": "921ee93ae994f046"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(f'Số bản ghi dữ liệu: {len(X)}')\n",
    "print(f'Số cột dữ liệu (tập X): {len(X.columns)}')"
   ],
   "id": "d7f32fdfb4a48260"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "X",
   "id": "b2ad5f60345d90da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "y",
   "id": "2c3677bf1916ced5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## II. One Hot Encoding và Label Encoding",
   "id": "42f6b6b7a9a62be1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_origin = X.copy()\n",
    "y_origin = y.copy()"
   ],
   "id": "ad34467a2036eb04"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# define model encoding\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "label_encoder = LabelEncoder()"
   ],
   "id": "83dd988d7a852602"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Giả sử X_origin là DataFrame ban đầu\n",
    "encode_cols = [\n",
    "    'BusinessTravel', 'Department', 'Education', 'EducationField',\n",
    "    'EnvironmentSatisfaction', 'Gender', 'JobInvolvement', 'JobLevel',\n",
    "    'JobRole', 'JobSatisfaction', 'MaritalStatus', 'Over18', 'OverTime',\n",
    "    'PerformanceRating', 'RelationshipSatisfaction', 'StockOptionLevel',\n",
    "    'WorkLifeBalance'\n",
    "]\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "# fit chuyển đổi luôn\n",
    "X_encoded_array = one_hot_encoder.fit_transform(X_origin[encode_cols])\n",
    "\n",
    "# Lấy tên cột mới sau khi mã hóa\n",
    "encoded_columns = one_hot_encoder.get_feature_names_out(encode_cols)\n",
    "\n",
    "# Tạo DataFrame từ mảng mã hóa\n",
    "X_encoded_df = pd.DataFrame(X_encoded_array, columns=encoded_columns, index=X_origin.index)\n",
    "\n",
    "# Gộp với phần dữ liệu còn lại\n",
    "X_encode = pd.concat([X_origin.drop(columns=encode_cols), X_encoded_df], axis=1)"
   ],
   "id": "8141fdf774b85ac8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "X_encode",
   "id": "f7e06c7257594c58"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "y_encode = label_encoder.fit_transform(y_origin)",
   "id": "499b1b82d7b63c7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "y_encode",
   "id": "ee9466b3e6b55795"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## III. Tự định nghĩa Class, Function",
   "id": "ca0513f867a56449"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class KNNClassifier:\n",
    "    def __init__(self, n_neighbors):\n",
    "        self.k = n_neighbors\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        # Đảm bảo y_train là mảng 1D\n",
    "        if y_train.ndim > 1:\n",
    "             # Cố gắng sửa lỗi y_train là ma trận 2D\n",
    "             self.y_train = y_train.flatten()\n",
    "        else:\n",
    "             self.y_train = y_train\n",
    "\n",
    "    def _predict_single(self, x_test_sample):\n",
    "        # Tính khoảng cách di từ x đến các xi trong tập Training\n",
    "        distances = np.linalg.norm(self.X_train - x_test_sample, axis=1)\n",
    "\n",
    "        # Tìm ra K chỉ số của các phần tử xi\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "\n",
    "        # Lấy các nhãn (y) tương ứng\n",
    "        k_neighbor_labels = self.y_train[k_indices]\n",
    "\n",
    "        # Lấy đầu ra dự đoán (tính trung bình và so sánh 0.5)\n",
    "        y_pred_avg = np.mean(k_neighbor_labels)\n",
    "\n",
    "        if (y_pred_avg >= 0.5):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        # Với mỗi x – unseen ở đầu vào (các phần tử trong tập Validation)\n",
    "        try:\n",
    "            y_preds = [self._predict_single(x) for x in X_test]\n",
    "            return np.array(y_preds)\n",
    "        except ValueError as e:\n",
    "            # Bắt lỗi nếu X_test và X_train có số cột (features) không khớp\n",
    "            print(f\"LỖI KHI DỰ ĐOÁN: Số chiều không khớp. Lỗi: {e}\")\n",
    "            print(f\"Shape X_train: {self.X_train.shape}, Shape X_test[0]: {X_test[0].shape}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"LỖI KHÔNG XÁC ĐỊNH: {e}\")\n",
    "            return None"
   ],
   "id": "d538afeba776f6e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "def fit_and_evaluate(model, X_train, y_train, X_test, y_test, description):\n",
    "    print(\"=\"*60)\n",
    "    print(f\"ĐANG HUẤN LUYỆN: {description}\")\n",
    "\n",
    "    try:\n",
    "        # Huấn luyện mô hình\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Dự đoán trên tập test (tính khoảng cách và lấy trung bình)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        if y_pred is not None:\n",
    "            # In kết quả\n",
    "            print(f\"Độ chính xác (Accuracy): {accuracy_score(y_test, y_pred):.4f}\")\n",
    "            print(\"\\nBáo cáo phân loại:\\n\", classification_report(y_test, y_pred, zero_division=0))\n",
    "            print(\"\\nMa trận nhầm lẫn:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"!!! GẶP LỖI: {e} !!!\")\n",
    "\n",
    "    print(\"=\"*60 + \"\\n\")"
   ],
   "id": "881cfbc383e6dc81"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## IV. Xây dựng mô hình",
   "id": "85046b7f7f1dcddc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Thực hiện với dữ liệu gốc",
   "id": "4700a1bbf566f375"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_copy_encode = X_encode.copy()\n",
    "y_copy_encode = y_encode.copy()"
   ],
   "id": "3272a6e6c465fe66"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_train_origin_t1, X_test_origin_t1, y_train_origin_t1, y_test_origin_t1 = train_test_split(\n",
    "    X_encode, y_encode, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train_origin_t2, X_test_origin_t2, y_train_origin_t2, y_test_origin_t2 = train_test_split(\n",
    "    X_encode, y_encode, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "X_train_origin_t3, X_test_origin_t3, y_train_origin_t3, y_test_origin_t3 = train_test_split(\n",
    "    X_encode, y_encode, test_size=0.4, random_state=42\n",
    ")"
   ],
   "id": "b7f869c5a4f2ad63"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.1. KNN (Numpy thuần)",
   "id": "aa98bcbea8442167"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "knn_model = KNNClassifier(n_neighbors=5)\n",
    "scaler = StandardScaler()"
   ],
   "id": "3066dc64d9cf3c0f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_train_origin_t1_std = scaler.fit_transform(X_train_origin_t1)\n",
    "X_test_origin_t1_std = scaler.transform(X_test_origin_t1)\n",
    "\n",
    "fit_and_evaluate(knn_model, X_train_origin_t1_std, y_train_origin_t1, X_test_origin_t1_std, y_test_origin_t1, \"KNN (Numpy thuần) trên dữ liệu gốc đã chuẩn hóa (train/test: 4/1)\")"
   ],
   "id": "e6bdda681baf2026"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_train_origin_t2_std = scaler.fit_transform(X_train_origin_t2)\n",
    "X_test_origin_t2_std = scaler.transform(X_test_origin_t2)\n",
    "\n",
    "fit_and_evaluate(knn_model, X_train_origin_t2_std, y_train_origin_t2, X_test_origin_t2_std, y_test_origin_t2, \"KNN (Numpy thuần) trên dữ liệu gốc đã chuẩn hóa (train/test: 7/3)\")"
   ],
   "id": "96359cef70e53165"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_train_origin_t3_std = scaler.fit_transform(X_train_origin_t3)\n",
    "X_test_origin_t3_std = scaler.transform(X_test_origin_t3)\n",
    "\n",
    "fit_and_evaluate(knn_model, X_train_origin_t3_std, y_train_origin_t3, X_test_origin_t3_std, y_test_origin_t3, \"KNN (Numpy thuần) trên dữ liệu gốc đã chuẩn hóa (train/test: 6/4)\")"
   ],
   "id": "ce61277d1cbbcab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.2. KNN (Thư viện)",
   "id": "2519991d06f3e7ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_lib = KNeighborsClassifier(n_neighbors=5)\n",
    "scaler = StandardScaler()"
   ],
   "id": "8feae2ab6e40f87b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_train_origin_t1_std = scaler.fit_transform(X_train_origin_t1)\n",
    "X_test_origin_t1_std = scaler.transform(X_test_origin_t1)\n",
    "\n",
    "fit_and_evaluate(knn_lib, X_train_origin_t1_std, y_train_origin_t1, X_test_origin_t1_std, y_test_origin_t1, \"KNN (Thư viện) trên dữ liệu gốc đã chuẩn hóa (train/test: 4/1)\")"
   ],
   "id": "c7b257068df0e635"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_train_origin_t2_std = scaler.fit_transform(X_train_origin_t2)\n",
    "X_test_origin_t2_std = scaler.transform(X_test_origin_t2)\n",
    "\n",
    "fit_and_evaluate(knn_lib, X_train_origin_t2_std, y_train_origin_t2, X_test_origin_t2_std, y_test_origin_t2, \"KNN (Thư viện) trên dữ liệu gốc đã chuẩn hóa (train/test: 7/3)\")"
   ],
   "id": "267e47bbff1f25e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_train_origin_t3_std = scaler.fit_transform(X_train_origin_t3)\n",
    "X_test_origin_t3_std = scaler.transform(X_test_origin_t3)\n",
    "\n",
    "fit_and_evaluate(knn_lib, X_train_origin_t3_std, y_train_origin_t3, X_test_origin_t3_std, y_test_origin_t3, \"KNN (Thư viện) trên dữ liệu gốc đã chuẩn hóa (train/test: 6/4)\")"
   ],
   "id": "576f5e267ef51da1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.3. Nhận xét",
   "id": "38dd06204e54276b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Kết quả của mô hình KNN bằng Numpy và mô hình KNN của thư viện (Scikit-learn) là giống hệt nhau ở cả 3 tỷ lệ chia.\n",
    "\n",
    "     - Split 4/1: Cả hai đều có Accuracy 0.8776, ma trận nhầm lẫn [[252, 3], [33, 6]].\n",
    "\n",
    "     - Split 7/3: Cả hai đều có Accuracy 0.8707, ma trận nhầm lẫn [[373, 7], [50, 11]].\n",
    "\n",
    "     - Split 6/4: Cả hai đều có Accuracy 0.8741, ma trận nhầm lẫn [[498, 9], [65, 16]]."
   ],
   "id": "4d693c06e8c5b6c7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Cả 3 tỷ lệ chia (4/1, 7/3, 6/4) đều cho thấy mô hình đang có 1 vài vấn đề:\n",
    "\n",
    "    - Chỉ số Accuracy (87-88%) rất cao và gây hiểu nhầm.\n",
    "\n",
    "    - Mô hình dự đoán Lớp 0 (Ở lại) cực kỳ tốt, với Recall gần như tuyệt đối (0.98 - 0.99).\n",
    "\n",
    "    - Mô hình dự đoán Lớp 1 (Nghỉ việc) cực kỳ tệ, với Recall rất thấp (chỉ từ 0.15 đến 0.20)."
   ],
   "id": "96d3bef9a754ec18"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Phân tích Ma trận nhầm lẫn (Ví dụ split 7/3): Ma trận [[373, 7], [50, 11]] cho thấy:\n",
    "\n",
    "    - Thực tế có 61 người nghỉ việc (hàng 2: 50 + 11).\n",
    "\n",
    "    - Mô hình đã bỏ sót 50 người (dự đoán sai họ \"Ở lại\").\n",
    "\n",
    "    - Mô hình chỉ bắt đúng 11 người (dự đoán đúng là \"Nghỉ việc\")."
   ],
   "id": "ac9bd535ee4e066d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Đánh giá: Mô hình này thất bại trong nhiệm vụ quan trọng nhất là \"phát hiện nhân viên nghỉ việc\". Nó quá thiên vị lớp đa số (Lớp 0) và gần như bỏ qua lớp thiểu số (Lớp 1). Chỉ số macro avg f1-score (chỉ ~0.60) mới phản ánh đúng hiệu suất \"tầm thường\" của mô hình.",
   "id": "bb54e31408e848c7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Đây không phải là overfit. Vấn đề của mô hình là làm tệ trên cả train và test đối với Lớp 1. Lý do là vì Dữ liệu mất cân bằng (Imbalanced Data) (khoảng 84% là Lớp 0). Mô hình đã học được rằng cách \"an toàn\" nhất để có Accuracy cao là luôn dự đoán Lớp 0.",
   "id": "b04f28e2a9927d85"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Thực hiện với dữ liệu đã giảm chiều",
   "id": "a976093e77333894"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.1. Giảm chiều sử dụng PCA",
   "id": "8c13f731d7b283ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Lấy data\n",
    "X_pca = X_encode.copy()\n",
    "y_pca = y_encode.copy()"
   ],
   "id": "1ad3d92e34e72ad0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Chia train/test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_t1_pca, X_test_t1_pca, y_train_t1_pca, y_test_t1_pca = train_test_split(X_pca, y_pca, test_size=0.2, random_state=42)\n",
    "X_train_t2_pca, X_test_t2_pca, y_train_t2_pca, y_test_t2_pca = train_test_split(X_pca, y_pca, test_size=0.3, random_state=42)\n",
    "X_train_t3_pca, X_test_t3_pca, y_train_t3_pca, y_test_t3_pca = train_test_split(X_pca, y_pca, test_size=0.4, random_state=42)"
   ],
   "id": "b52cf0dc84866755"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Chuẩn hóa\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_t1_pca_std = scaler.fit_transform(X_train_t1_pca)\n",
    "X_test_t1_pca_std = scaler.transform(X_test_t1_pca)\n",
    "\n",
    "X_train_t2_pca_std = scaler.fit_transform(X_train_t2_pca)\n",
    "X_test_t2_pca_std = scaler.transform(X_test_t2_pca)\n",
    "\n",
    "X_train_t3_pca_std = scaler.fit_transform(X_train_t3_pca)\n",
    "X_test_t3_pca_std = scaler.transform(X_test_t3_pca)"
   ],
   "id": "eb30949229b21147"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Giảm chiều\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_n6 = PCA(n_components=6)\n",
    "\n",
    "X_train_t1_after_pca_n6_std = pca_n6.fit_transform(X_train_t1_pca_std)\n",
    "X_test_t1_after_pca_n6_std = pca_n6.transform(X_test_t1_pca_std)\n",
    "\n",
    "X_train_t2_after_pca_n6_std = pca_n6.fit_transform(X_train_t2_pca_std)\n",
    "X_test_t2_after_pca_n6_std = pca_n6.transform(X_test_t2_pca_std)\n",
    "\n",
    "X_train_t3_after_pca_n6_std = pca_n6.fit_transform(X_train_t3_pca_std)\n",
    "X_test_t3_after_pca_n6_std = pca_n6.transform(X_test_t3_pca_std)"
   ],
   "id": "6982a476de1acb1f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 2.1.1. KNN (Numpy thuần)",
   "id": "a55d56a987ce0ddd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "knn_model = KNNClassifier(n_neighbors=5)",
   "id": "b109e0f1bfdb2a68"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "fit_and_evaluate(knn_model, X_train_t1_after_pca_n6_std, y_train_t1_pca, X_test_t1_after_pca_n6_std, y_test_t1_pca, \"KNN (Numpy thuần) - PCA n=6 đã chuẩn hóa (train/test: 4/1)\")",
   "id": "ca12fa892e84be2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "fit_and_evaluate(knn_model, X_train_t2_after_pca_n6_std, y_train_t2_pca, X_test_t2_after_pca_n6_std, y_test_t2_pca, \"KNN (Numpy thuần) - PCA n=6 đã chuẩn hóa (train/test: 7/3)\")",
   "id": "c890d7ce93191adc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "fit_and_evaluate(knn_model, X_train_t3_after_pca_n6_std, y_train_t3_pca, X_test_t3_after_pca_n6_std, y_test_t3_pca, \"KNN (Numpy thuần) - PCA n=6 đã chuẩn hóa (train/test: 6/4)\")",
   "id": "65627c1c4521c41c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 2.1.2. KNN (Thư viện)",
   "id": "bb38281f1036526f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "knn_lib = KNeighborsClassifier(n_neighbors=5)",
   "id": "28539786540e6657"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "fit_and_evaluate(knn_lib, X_train_t1_after_pca_n6_std, y_train_t1_pca, X_test_t1_after_pca_n6_std, y_test_t1_pca, \"KNN (Thư viện) - PCA n=6 đã chuẩn hóa (train/test: 4/1)\")",
   "id": "2e2ce76b18d14d38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "fit_and_evaluate(knn_lib, X_train_t2_after_pca_n6_std, y_train_t2_pca, X_test_t2_after_pca_n6_std, y_test_t2_pca, \"KNN (Thư viện) - PCA n=6 đã chuẩn hóa (train/test: 7/3)\")",
   "id": "df0bb0bdf8761113"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "fit_and_evaluate(knn_lib, X_train_t3_after_pca_n6_std, y_train_t3_pca, X_test_t3_after_pca_n6_std, y_test_t3_pca, \"KNN (Thư viện) - PCA n=6 đã chuẩn hóa (train/test: 6/4)\")",
   "id": "250ab6aa81370237"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.2. Giảm chiều sử dụng LDA",
   "id": "6a0ddb350c12f3b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Lấy data\n",
    "X_lda = X_encode.copy()\n",
    "y_lda = y_encode.copy()"
   ],
   "id": "582c53c3ee60b605"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Chia train/test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_t1_lda, X_test_t1_lda, y_train_t1_lda, y_test_t1_lda = train_test_split(X_lda, y_lda, test_size=0.2, random_state=42)\n",
    "X_train_t2_lda, X_test_t2_lda, y_train_t2_lda, y_test_t2_lda = train_test_split(X_lda, y_lda, test_size=0.3, random_state=42)\n",
    "X_train_t3_lda, X_test_t3_lda, y_train_t3_lda, y_test_t3_lda = train_test_split(X_lda, y_lda, test_size=0.4, random_state=42)"
   ],
   "id": "c657048d488efe9e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Chuẩn hóa\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_t1_lda_std = scaler.fit_transform(X_train_t1_lda)\n",
    "X_test_t1_lda_std = scaler.transform(X_test_t1_lda)\n",
    "\n",
    "X_train_t2_lda_std = scaler.fit_transform(X_train_t2_lda)\n",
    "X_test_t2_lda_std = scaler.transform(X_test_t2_lda)\n",
    "\n",
    "X_train_t3_lda_std = scaler.fit_transform(X_train_t3_lda)\n",
    "X_test_t3_lda_std = scaler.transform(X_test_t3_lda)"
   ],
   "id": "6982503e8c513257"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Giảm chiều\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "num_classes = y_origin.value_counts()\n",
    "number_classes = len(num_classes)\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components = number_classes - 1)\n",
    "\n",
    "X_train_t1_after_lda_std = lda.fit_transform(X_train_t1_lda_std, y_train_t1_lda)\n",
    "X_test_t1_after_lda_std = lda.transform(X_test_t1_lda_std)\n",
    "\n",
    "X_train_t2_after_lda_std = lda.fit_transform(X_train_t2_lda_std, y_train_t2_lda)\n",
    "X_test_t2_after_lda_std = lda.transform(X_test_t2_lda_std)\n",
    "\n",
    "X_train_t3_after_lda_std = lda.fit_transform(X_train_t3_lda_std, y_train_t3_lda)\n",
    "X_test_t3_after_lda_std = lda.transform(X_test_t3_lda_std)"
   ],
   "id": "457f75a83cfdbf2c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 2.2.1. KNN (Numpy thuần)",
   "id": "7f413252b6855361"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "knn_model = KNNClassifier(n_neighbors=5)",
   "id": "42c6024fab8b40c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "fit_and_evaluate(knn_model, X_train_t1_after_lda_std, y_train_t1_lda, X_test_t1_after_lda_std, y_test_t1_lda, \"KNN (Numpy thuần) - LDA đã chuẩn hóa (train/test: 4/1)\")",
   "id": "4631773d2455ee3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "fit_and_evaluate(knn_model, X_train_t2_after_lda_std, y_train_t2_lda, X_test_t2_after_lda_std, y_test_t2_lda, \"KNN (Numpy thuần) - LDA đã chuẩn hóa (train/test: 7/3)\")",
   "id": "9d22147fc1706a3d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "fit_and_evaluate(knn_model, X_train_t3_after_lda_std, y_train_t3_lda, X_test_t3_after_lda_std, y_test_t3_lda, \"KNN (Numpy thuần) - LDA đã chuẩn hóa (train/test: 6/4)\")",
   "id": "acf8697725d4b57e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 2.2.2. KNN (Thư viện)",
   "id": "80c4f52a7c575766"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "knn_lib = KNeighborsClassifier(n_neighbors=5)",
   "id": "c8adaba0b34cb598"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "fit_and_evaluate(knn_lib, X_train_t1_after_lda_std, y_train_t1_lda, X_test_t1_after_lda_std, y_test_t1_lda, \"KNN (Thư viện) - LDA đã chuẩn hóa (train/test: 4/1)\")",
   "id": "f1c13fd0569d81ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "fit_and_evaluate(knn_lib, X_train_t2_after_lda_std, y_train_t2_lda, X_test_t2_after_lda_std, y_test_t2_lda, \"KNN (Thư viện) - LDA đã chuẩn hóa (train/test: 7/3)\")",
   "id": "ac1418288ad9d34"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "fit_and_evaluate(knn_lib, X_train_t3_after_lda_std, y_train_t3_lda, X_test_t3_after_lda_std, y_test_t3_lda, \"KNN (Thư viện) - LDA đã chuẩn hóa (train/test: 6/4)\")",
   "id": "4fd7d76220c6790d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.3. Nhận xét",
   "id": "f27537448664fde4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- So với kết quả của Dữ liệu gốc (81 cột) ở lượt trước (có macro avg f1-score ~ 0.60):\n",
    "\n",
    "  + Kết quả của PCA n=6 (giảm xuống còn 6 cột) thậm chí còn tệ hơn.\n",
    "\n",
    "  + Ví dụ ở split 7/3, macro avg f1-score là 0.59, và f1-score của Lớp 1 (Nghỉ việc) chỉ là 0.28.\n",
    "\n",
    "  + Ma trận nhầm lẫn [[355, 25], [47, 14]] cho thấy mô hình đã bỏ sót 47/61 trường hợp nghỉ việc VÀ còn dự đoán sai 25 trường hợp không nghỉ.\n",
    "=> Đánh giá: Việc giảm chiều xuống chỉ còn 6 thành phần bằng PCA (một phương pháp không giám sát) đã làm mất quá nhiều thông tin quan trọng cần thiết để phân biệt hai lớp. PCA chỉ quan tâm đến \"phương sai\" chung, và 6 cột này rõ ràng là không đủ để mô tả bài toán"
   ],
   "id": "53f4f5e571b7a90"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Kết quả của LDA vượt trội hơn hẳn so với cả PCA và Dữ liệu gốc.\n",
    "\n",
    "- Ví dụ ở split 7/3 (kết quả tệ nhất của LDA):\n",
    "\n",
    "    - macro avg f1-score là 0.67 (so với 0.59 của PCA và 0.60 của Dữ liệu gốc).\n",
    "\n",
    "    - f1-score của Lớp 1 là 0.42 (so với 0.28 của PCA và ~0.28 của Dữ liệu gốc).\n",
    "\n",
    "- Ví dụ ở split 6/4 (kết quả tốt nhất của LDA):\n",
    "\n",
    "    - macro avg f1-score tăng vọt lên 0.73.\n",
    "\n",
    "    - f1-score của Lớp 1 đạt 0.53.\n",
    "\n",
    "    - Ma trận nhầm lẫn [[477, 30], [41, 40]] cho thấy một sự cải thiện vượt bậc: Mô hình đã bắt đúng 40 trong số 81 trường hợp (tỷ lệ recall 0.49), và có precision là 0.57.\n",
    "\n",
    "=> Đánh giá: LDA là phương pháp giảm chiều phù hợp hơn hẳn cho bài toán này.\n",
    "\n",
    "Do PCA là không giám sát (unsupervised), nó không quan tâm đến nhãn Yes/No. Nó chỉ giữ lại các chiều có phương sai lớn nhất.\n",
    "\n",
    "Ngược lại, LDA (Linear Discriminant Analysis) là có giám sát (supervised). Mục tiêu của nó chính là tìm ra các chiều mới (1 chiều duy nhất trong bài toán nhị phân này) sao cho độ phân tách giữa hai lớp Yes và No là lớn nhất. LDA đã thành công trong việc \"chiếu\" dữ liệu 81 chiều xuống 1 chiều duy nhất mà vẫn giữ lại được thông tin quan trọng nhất để phân loại."
   ],
   "id": "c56f68d60fad0a2f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Đây không phải là Overfitting.\n",
    "\n",
    "Cả 3 phương pháp (Dữ liệu gốc, PCA, LDA) đều cho thấy cùng một vấn đề: Mô hình bị thiên vị (biased) và học chưa tới (underfitting) đối với Lớp 1.\n",
    "\n",
    "Lý do vẫn là dữ liệu mất cân bằng (imbalanced data). Mặc dù LDA đã cải thiện đáng kể kết quả (vì nó tập trung vào việc tách lớp), nó vẫn chưa thể giải quyết triệt để vấn đề là có quá ít mẫu Lớp 1 để học."
   ],
   "id": "c71cf9abd831dc23"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "\"Hiệu chỉnh\" (regularization) cho KNN chính là việc chọn ra K tối ưu. Việc này giúp cân bằng giữa Bias và Variance.",
   "id": "a9048ba376304c05"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "=> Biện pháp cải thiện (Giải quyết gốc rễ vấn đề)\n",
    "\n",
    "- Kết hợp LDA + SMOTE:\n",
    "\n",
    "    - Chia X_train_full, X_test_full, y_train_full, y_test_full.\n",
    "\n",
    "    - fit LDA trên X_train_full, y_train_full.\n",
    "\n",
    "    - transform X_train_full để tạo ra X_train_lda.\n",
    "\n",
    "    - transform X_test_full để tạo ra X_test_lda.\n",
    "\n",
    "    - Áp dụng SMOTE chỉ lên X_train_lda và y_train_full để tạo ra X_train_resampled và y_train_resampled đã cân bằng.\n",
    "\n",
    "    - Huấn luyện KNN (với K tối ưu) trên (X_train_resampled, y_train_resampled).\n",
    "\n",
    "    - Đánh giá trên (X_test_lda, y_test_full)."
   ],
   "id": "ffb53fd61e5f6b46"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## V. Trực quan",
   "id": "7e34e3bb44e6cb0a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def helper_and_plot(X_train, X_test, y_train, y_test, model = None, command = 'Default command', reduce_name = None, n_components = 2):\n",
    "    from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "    import time\n",
    "    if reduce_name == 'PCA':\n",
    "        model_rd = PCA(n_components=n_components)\n",
    "        X_train = model_rd.fit_transform(X_train)\n",
    "        X_test = model_rd.transform(X_test)\n",
    "    elif reduce_name == 'LDA':\n",
    "        model_rd = LinearDiscriminantAnalysis(n_components=n_components)\n",
    "        X_train = model_rd.fit_transform(X_train, y_train)\n",
    "        X_test = model_rd.transform(X_test)\n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_prediction = model.predict(X_test)\n",
    "    end_time = time.time()\n",
    "    y_prediction_train = model.predict(X_train)\n",
    "\n",
    "\n",
    "    def plot_prediction_vs_true(y_pred, y_test, title=\"So sánh Dự đoán và Thực tế\"):\n",
    "        y_pred = np.array(y_pred).flatten()\n",
    "        y_test = np.array(y_test).flatten()\n",
    "\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        x = np.arange(len(y_test))\n",
    "\n",
    "        # Điểm đúng và sai\n",
    "        correct = (y_pred == y_test)\n",
    "\n",
    "        plt.scatter(x[correct], y_test[correct], color='green', label='Dự đoán đúng', marker='o')\n",
    "        plt.scatter(x[~correct], y_test[~correct], color='red', label='Dự đoán sai', marker='x')\n",
    "\n",
    "        plt.title(title, fontsize=14)\n",
    "        plt.xlabel(\"Chỉ số mẫu (Index)\")\n",
    "        plt.ylabel(\"Nhãn (0/1)\")\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle='--', alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # def plot_confusion_heatmap(y_pred, y_test, title=\"Ma trận nhầm lẫn\"):\n",
    "    #     cm = confusion_matrix(y_test, y_pred)\n",
    "    #     sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    #     plt.title(title)\n",
    "    #     plt.xlabel(\"Dự đoán\")\n",
    "    #     plt.ylabel(\"Thực tế\")\n",
    "    #     plt.show()\n",
    "\n",
    "\n",
    "    print()\n",
    "    print('=' * 20, command, '=' * 20)\n",
    "    print(f'X_train: {X_train.shape} X_test: {X_test.shape}')\n",
    "    print(f'Total time: {end_time - start_time}')\n",
    "    print(f'Accuracy of model {model.__class__.__name__}: {accuracy_score(y_prediction, y_test)}')\n",
    "    print(f'Accuracy train of model {model.__class__.__name__}: {accuracy_score(y_prediction_train, y_train)}')\n",
    "    print(f'Confuse matrix: \\n{confusion_matrix(y_test, y_prediction)}')\n",
    "    print('=' * 20, command, '=' * 20)\n",
    "    print()\n",
    "\n",
    "    plot_prediction_vs_true(y_prediction, y_test)"
   ],
   "id": "ed977f4f8855ed4c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_copy_encode = X_encode.copy()\n",
    "y_copy_encode = y_encode.copy()"
   ],
   "id": "93641d2edc75d252"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# --- TÁCH DỮ LIỆU ---\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X_copy_encode, y_copy_encode, test_size = 0.4, random_state = 42\n",
    ")\n",
    "\n",
    "# --- TIỀN XỬ LÝ (Chuẩn hóa & Giảm chiều) ---\n",
    "# Chuẩn hóa\n",
    "scaler = StandardScaler().fit(X_train_val)\n",
    "X_train_val_std = scaler.transform(X_train_val)\n",
    "X_test_std = scaler.transform(X_test) # Chuẩn hóa tập test\n",
    "\n",
    "# LUỒNG 1: PCA (n=6)\n",
    "print(\"\\n--- BẮT ĐẦU LUỒNG 1: PCA (n=6) ---\")\n",
    "\n",
    "# 1a. Áp dụng PCA\n",
    "pca = PCA(n_components=6).fit(X_train_val_std)\n",
    "X_train_pca = pca.transform(X_train_val_std)\n",
    "X_test_pca = pca.transform(X_test_std)\n",
    "\n",
    "# 1b. Tìm K tốt nhất cho PCA\n",
    "print(\"Đang tìm K tối ưu cho dữ liệu PCA...\")\n",
    "grid_search_pca = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    {'n_neighbors': list(range(1, 32, 2))},\n",
    "    cv=5,\n",
    "    scoring='f1_weighted',\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search_pca.fit(X_train_pca, y_train_val)\n",
    "best_k_pca = grid_search_pca.best_params_['n_neighbors']\n",
    "print(f\"Giá trị K tốt nhất cho PCA (n=6) là: {best_k_pca}\")\n",
    "\n",
    "# 1c. Chạy helper_and_plot với K tốt nhất\n",
    "helper_and_plot(\n",
    "    X_train_pca, X_test_pca, y_train_val, y_test,\n",
    "    model = KNeighborsClassifier(n_neighbors=best_k_pca),\n",
    "    command = f'KNN (K={best_k_pca}) với dữ liệu PCA (n=6)',\n",
    "    reduce_name = None # ĐÃ GIẢM CHIỀU RỒI\n",
    ")\n",
    "\n",
    "# LUỒNG 2: LDA (n=1)\n",
    "print(\"\\n--- BẮT ĐẦU LUỒNG 2: LDA (n=1) ---\")\n",
    "\n",
    "# 2a. Áp dụng LDA\n",
    "# n_components=1 vì đây là bài toán 2 lớp\n",
    "lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "# LDA là \"có giám sát\", nên cần y_train_val khi fit\n",
    "lda.fit(X_train_val_std, y_train_val)\n",
    "\n",
    "# Transform cả hai tập\n",
    "X_train_lda = lda.transform(X_train_val_std)\n",
    "X_test_lda = lda.transform(X_test_std)\n",
    "print(f\"Đã giảm chiều xuống {X_train_lda.shape[1]} cột bằng LDA.\")\n",
    "\n",
    "# 2b. Tìm K tốt nhất cho LDA\n",
    "print(\"Đang tìm K tối ưu cho dữ liệu LDA...\")\n",
    "grid_search_lda = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    {'n_neighbors': list(range(1, 32, 2))},\n",
    "    cv=5,\n",
    "    scoring='f1_weighted',\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search_lda.fit(X_train_lda, y_train_val)\n",
    "best_k_lda = grid_search_lda.best_params_['n_neighbors']\n",
    "print(f\"Giá trị K tốt nhất cho LDA (n=1) là: {best_k_lda}\")\n",
    "\n",
    "# 2c. Chạy helper_and_plot với K tốt nhất\n",
    "helper_and_plot(\n",
    "    X_train_lda, X_test_lda, y_train_val, y_test,\n",
    "    model = KNeighborsClassifier(n_neighbors=best_k_lda),\n",
    "    command = f'KNN (K={best_k_lda}) với dữ liệu LDA (n=1)',\n",
    "    reduce_name = None # ĐÃ GIẢM CHIỀU RỒI\n",
    ")"
   ],
   "id": "231d1bff64932830"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Đánh giá mô hình có phù hợp không?\n",
    "- Nhận định: Mô hình KNN, ngay cả khi kết hợp với LDA, chỉ phù hợp ở mức độ nhất định nhưng chưa phải là mô hình tối ưu cho bài toán này."
   ],
   "id": "5471171c969ed667"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "=> Mô hình \"phù hợp một phần\"\n",
    "- Mô hình thực hiện rất tốt nhiệm vụ dự đoán Lớp 0 (Nhân viên ở lại).\n",
    "\n",
    "- Chỉ số Accuracy tổng thể cao (gần 88%), cho thấy mô hình đã học được phần lớn dữ liệu (là Lớp 0)."
   ],
   "id": "89065a534346117e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "=> Mô hình \"chưa tối ưu\"\n",
    "\n",
    "- Mục tiêu của bài toán: Mục tiêu kinh doanh thực tế không phải là tìm ra người ở lại, mà là tìm ra người sắp nghỉ (Lớp 1) để có biện pháp can thiệp.\n",
    "\n",
    "- Kết quả thực tế: Mô hình thất bại nặng ở mục tiêu này."
   ],
   "id": "31a9125f0f795dca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "=> Nguyên nhân mô hình hoạt động như vậy là do Dữ liệu mất cân bằng (Imbalanced Data).\n",
    "\n",
    "- Lớp 0 (Ở lại) chiếm tới ~84% dữ liệu.\n",
    "\n",
    "- Lớp 1 (Nghỉ việc) chỉ chiếm ~16%.\n",
    "\n",
    "- Do đó, mô hình KNN (một thuật toán dựa trên khoảng cách) bị \"thiên vị\" (biased). Nó học được rằng cách \"an toàn\" nhất để đạt được Accuracy cao là cứ dự đoán phần lớn là Lớp 0. Nó không có đủ mẫu Lớp 1 để học và phân biệt một cách hiệu quả.\n",
    "\n",
    "=> Kết luận: Một mô hình chỉ phù hợp khi nó giải quyết được bài toán kinh doanh. Mặc dù Accuracy 88% nghe có vẻ cao, nhưng một mô hình bỏ sót hơn 50% số ca nghỉ việc là không thể chấp nhận được trong thực tế. Vì vậy, mô hình này là chưa phù hợp."
   ],
   "id": "750e733ba2ac7dc5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
